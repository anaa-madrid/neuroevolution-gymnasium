{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f85c3d3",
   "metadata": {},
   "source": [
    "NOMBRES:\n",
    "\n",
    "Javier Iglesias \n",
    "\n",
    "Ana Madrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce62d5d",
   "metadata": {},
   "source": [
    "### Recursos\n",
    "\n",
    "Problemas interesantes para Aprendizaje por refuerzo\n",
    " * Gymnasium: https://gymnasium.farama.org/environments/box2d/\n",
    " * Solución del Lunar Lander con DQN: https://shiva-verma.medium.com/solving-lunar-lander-openaigym-reinforcement-learning-785675066197\n",
    " * Otra solución: https://wingedsheep.com/lunar-lander-dqn/ y https://github.com/wingedsheep/blog/blob/main/lunar-lander-dqn/lunar_lander_dqn_blog.ipynb\n",
    " * The Nature of Code: https://youtu.be/lu5ul7z4icQ\n",
    " * Librería para neuroevolución: https://pypi.org/project/nevopy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ee95ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium[box2d] in c:\\users\\anadr\\anaconda3\\lib\\site-packages (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\anadr\\anaconda3\\lib\\site-packages (from gymnasium[box2d]) (1.22.4)\n",
      "Requirement already satisfied: jax-jumpy>=0.2.0 in c:\\users\\anadr\\anaconda3\\lib\\site-packages (from gymnasium[box2d]) (1.0.0)\n",
      "Requirement already satisfied: gymnasium-notices>=0.0.1 in c:\\users\\anadr\\anaconda3\\lib\\site-packages (from gymnasium[box2d]) (0.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\anadr\\anaconda3\\lib\\site-packages (from gymnasium[box2d]) (4.8.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\anadr\\anaconda3\\lib\\site-packages (from gymnasium[box2d]) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\anadr\\anaconda3\\lib\\site-packages (from gymnasium[box2d]) (4.8.0)\n",
      "Requirement already satisfied: swig==4.* in c:\\users\\anadr\\anaconda3\\lib\\site-packages (from gymnasium[box2d]) (4.1.1)\n",
      "Requirement already satisfied: pygame==2.1.3.dev8 in c:\\users\\anadr\\anaconda3\\lib\\site-packages (from gymnasium[box2d]) (2.1.3.dev8)\n",
      "Requirement already satisfied: box2d-py==2.3.5 in c:\\users\\anadr\\anaconda3\\lib\\site-packages (from gymnasium[box2d]) (2.3.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\anadr\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium[box2d]) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gymnasium[box2d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b40957f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anadr\\Anaconda3\\lib\\site-packages\\ipykernel\\eventloops.py:256: RuntimeWarning: coroutine 'Kernel.do_one_iteration' was never awaited\n",
      "  self.func()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "# prueba lunar lander por humano\n",
    "# apartado A de la práctica\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"LunarLander-v2\", render_mode=\"rgb_array\")\n",
    "\n",
    "import numpy as np\n",
    "import pygame\n",
    "import gymnasium.utils.play\n",
    "\n",
    "lunar_lander_keys = {\n",
    "    (pygame.K_UP,): 2,\n",
    "    (pygame.K_LEFT,): 1,\n",
    "    (pygame.K_RIGHT,): 3,\n",
    "}\n",
    "gymnasium.utils.play.play(env, zoom=3, keys_to_action=lunar_lander_keys, noop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8cbb07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#observacion=[x, y, vx, vy, ang, vang, pataiz, parader]\n",
    "#acciones=[nada, derecho, central, izquierdo]\n",
    " \n",
    "\n",
    "def policy (observation):\n",
    "    if observation[3]<-0.2:\n",
    "        print('⬆︎',end='')\n",
    "        return 2\n",
    "    \n",
    "    \n",
    "    if observation[4]<-0.1:\n",
    "        print('⬅︎',end='')\n",
    "        return 1 \n",
    "        \n",
    "    if observation[5]<-0.1:\n",
    "        print('⬅︎',end='')\n",
    "        return 1\n",
    "    \n",
    "    if observation[2]<-0.1:\n",
    "        print('➡︎',end='')\n",
    "        return 3\n",
    "    \n",
    "    if observation[0]<-0.1:\n",
    "        print('➡︎',end='')\n",
    "        return 3\n",
    " \n",
    "    if observation[4]> 0.1:\n",
    "        print('➡︎',end='')\n",
    "        return 3\n",
    "\n",
    "    if observation[5]>0.1:\n",
    "        print('➡︎',end='')\n",
    "        return 3\n",
    "\n",
    "    if observation[2]>0.1:\n",
    "        print('⬅︎',end='')\n",
    "        return 1\n",
    "    \n",
    "    if observation[0]>0.1:\n",
    "        print('⬅︎',end='')\n",
    "        return 1\n",
    "    \n",
    "    if observation[3]>0.1:\n",
    "        print('⬇︎',end='')\n",
    "        return 0\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94d8a866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡︎➡︎➡︎➡︎➡︎➡︎⬅︎➡︎⬅︎➡︎⬅︎➡︎⬅︎➡︎⬅︎➡︎⬅︎➡︎⬅︎➡︎⬅︎➡︎⬅︎➡︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬆︎➡︎➡︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎➡︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎➡︎➡︎⬆︎➡︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎➡︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬅︎➡︎⬆︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬆︎⬅︎⬅︎⬆︎⬅︎⬆︎⬆︎⬆︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎➡︎➡︎⬆︎➡︎⬆︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬆︎⬆︎⬅︎⬆︎⬆︎⬅︎⬅︎⬆︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬅︎➡︎⬆︎⬅︎⬆︎⬆︎⬆︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬅︎⬅︎⬆︎⬅︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬅︎⬆︎⬆︎➡︎⬆︎⬅︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎⬅︎➡︎➡︎➡︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎260.5318062615744 0.6302659031307871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "260.5318062615744"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prueba lunar lander por agente\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n",
    "\n",
    "def run ():\n",
    "    #observation, info = env.reset(seed=42)\n",
    "    observation, info = env.reset()\n",
    "    ite = 0\n",
    "    racum = 0\n",
    "    while True:\n",
    "        action = policy(observation)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        \n",
    "        racum += reward\n",
    "\n",
    "        if terminated or truncated:\n",
    "            r = (racum+1000) / 2000\n",
    "            print(racum, r)\n",
    "            return racum\n",
    "    \n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "558c20f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎➡︎➡︎⬆︎➡︎⬆︎⬆︎➡︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬅︎⬆︎➡︎➡︎⬆︎⬅︎⬆︎⬆︎⬆︎⬆︎⬅︎⬆︎➡︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬅︎⬆︎➡︎⬆︎➡︎⬆︎➡︎➡︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬅︎⬆︎⬆︎⬆︎⬅︎⬅︎⬆︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬆︎⬅︎⬆︎-79.69219508526355 0.46015390245736826\n",
      "⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎➡︎⬆︎⬆︎⬅︎⬆︎➡︎⬆︎⬆︎⬅︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎⬅︎⬆︎⬆︎➡︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬅︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬅︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎➡︎➡︎⬆︎⬆︎⬆︎➡︎➡︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎⬆︎⬆︎⬅︎⬆︎➡︎⬆︎➡︎⬆︎⬅︎➡︎⬆︎⬆︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎⬆︎⬆︎➡︎⬅︎⬆︎⬆︎⬆︎⬅︎⬆︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎➡︎210.15853303734923 0.6050792665186746\n",
      "⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬅︎⬅︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬆︎➡︎⬅︎⬆︎⬆︎➡︎⬆︎⬅︎➡︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎⬅︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎➡︎➡︎⬆︎⬆︎⬆︎➡︎➡︎⬆︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬆︎⬅︎⬅︎⬆︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎➡︎⬆︎⬅︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬆︎⬆︎⬅︎⬆︎⬆︎⬅︎⬅︎⬆︎⬅︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎-58.000850823024614 0.4709995745884877\n",
      "⬅︎⬅︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬆︎⬅︎➡︎⬆︎⬅︎⬆︎⬆︎⬆︎➡︎⬅︎⬆︎➡︎⬆︎➡︎⬆︎➡︎➡︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬆︎⬅︎⬅︎⬆︎⬆︎⬆︎⬅︎⬅︎⬆︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎➡︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎➡︎➡︎⬆︎⬅︎⬆︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬅︎➡︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬅︎⬅︎⬆︎⬅︎⬆︎➡︎➡︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎➡︎⬆︎⬆︎⬅︎⬆︎⬆︎➡︎⬆︎⬆︎⬅︎⬅︎⬆︎⬆︎➡︎⬆︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎⬅︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎⬆︎➡︎⬆︎⬅︎➡︎⬆︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬆︎⬅︎⬅︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬆︎⬅︎➡︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬅︎⬆︎⬅︎⬆︎➡︎⬅︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎➡︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎➡︎⬆︎⬆︎⬅︎⬆︎⬅︎➡︎⬆︎⬅︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬅︎⬆︎⬆︎➡︎⬅︎➡︎➡︎➡︎➡︎⬆︎➡︎➡︎➡︎⬅︎⬅︎⬅︎➡︎➡︎➡︎⬅︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎⬅︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎205.93903116423536 0.6029695155821176\n",
      "⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎➡︎⬆︎⬆︎⬅︎⬆︎⬆︎➡︎⬆︎⬅︎➡︎⬆︎⬅︎⬆︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎➡︎➡︎⬆︎⬆︎➡︎⬆︎➡︎⬅︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬅︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎➡︎⬆︎➡︎⬆︎⬅︎⬆︎⬆︎➡︎⬆︎⬅︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬅︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎➡︎⬅︎⬆︎⬆︎⬆︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬆︎➡︎⬅︎⬆︎⬆︎➡︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎➡︎➡︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎➡︎➡︎231.13925446805467 0.6155696272340274\n",
      "⬆︎➡︎⬆︎⬆︎⬆︎➡︎➡︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎⬅︎⬆︎➡︎⬆︎⬆︎⬅︎⬆︎⬅︎➡︎⬆︎⬆︎⬅︎⬅︎⬆︎⬆︎⬅︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬅︎⬆︎⬆︎➡︎⬆︎⬅︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎⬆︎➡︎➡︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬆︎⬆︎➡︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬆︎⬅︎⬆︎⬆︎⬅︎⬅︎⬆︎➡︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎⬆︎➡︎➡︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬅︎⬆︎⬅︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎➡︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎⬅︎⬅︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬅︎⬆︎⬆︎⬆︎⬅︎⬅︎⬆︎⬅︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬅︎⬅︎⬆︎⬅︎⬆︎➡︎⬆︎⬆︎⬅︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬅︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬅︎⬅︎⬆︎⬆︎⬅︎➡︎⬆︎⬆︎➡︎⬅︎⬆︎⬅︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎⬅︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎⬅︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬅︎⬆︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎➡︎⬆︎⬆︎➡︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬅︎⬆︎⬆︎⬅︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎⬅︎⬅︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎➡︎218.25179309526095 0.6091258965476304\n",
      "➡︎⬆︎➡︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎➡︎⬆︎⬆︎⬅︎⬅︎⬆︎➡︎⬆︎⬆︎⬅︎⬆︎⬅︎⬅︎⬆︎⬆︎⬆︎⬅︎⬅︎⬆︎⬅︎⬅︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎➡︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬆︎⬅︎⬆︎⬆︎⬆︎⬅︎⬅︎⬆︎⬅︎⬆︎⬅︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎➡︎➡︎⬆︎⬆︎➡︎➡︎⬆︎⬆︎⬅︎➡︎⬆︎⬅︎⬆︎⬆︎➡︎⬆︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬅︎⬆︎⬆︎➡︎⬅︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬆︎⬆︎➡︎➡︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎➡︎➡︎➡︎235.6197455955737 0.6178098727977869\n",
      "⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬅︎⬆︎⬆︎➡︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬅︎⬆︎⬅︎⬅︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬅︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎➡︎➡︎➡︎235.28320723213236 0.6176416036160661\n",
      "⬇︎⬇︎⬇︎⬇︎⬇︎⬇︎⬇︎⬇︎⬇︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎➡︎⬆︎⬅︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎➡︎➡︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬅︎⬆︎⬆︎⬆︎➡︎⬅︎⬆︎⬆︎⬅︎⬆︎➡︎⬅︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎➡︎⬆︎⬅︎⬆︎⬅︎⬅︎⬆︎⬅︎⬆︎➡︎⬆︎⬆︎⬆︎⬅︎⬆︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬅︎⬅︎⬆︎⬆︎⬆︎⬆︎⬅︎⬆︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬅︎⬅︎⬆︎⬅︎⬆︎➡︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬆︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬆︎⬅︎⬆︎⬅︎⬅︎⬆︎➡︎⬆︎⬆︎⬆︎⬅︎➡︎⬆︎⬅︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎➡︎➡︎⬆︎⬆︎⬆︎⬅︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎➡︎➡︎231.65479215542035 0.6158273960777102\n",
      "⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎⬆︎➡︎⬆︎⬆︎⬆︎⬆︎⬅︎⬆︎⬆︎➡︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬅︎⬆︎⬆︎⬅︎⬅︎⬆︎⬆︎⬅︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎⬅︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬅︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬅︎⬆︎⬅︎⬆︎⬅︎⬆︎⬆︎⬆︎⬅︎⬆︎⬅︎⬅︎⬆︎⬆︎➡︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎➡︎⬆︎⬆︎⬆︎⬆︎⬆︎⬅︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎⬅︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎⬆︎➡︎⬆︎⬆︎⬆︎➡︎⬆︎➡︎⬆︎⬆︎⬆︎⬆︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎⬅︎➡︎243.39279660610399 0.621696398303052\n",
      "167.37461074458423\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "r = 0\n",
    "for _ in range(N):\n",
    "    r += run()\n",
    "    \n",
    "print(r/N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1a55ef",
   "metadata": {},
   "source": [
    "# Neuroevolución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a34dfffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Perceptron:\n",
    "    def __init__(self, ninput, noutput):\n",
    "        self.ninput = ninput\n",
    "        self.noutput = noutput\n",
    "        self.w = np.random.rand(ninput,noutput)-0.5\n",
    "        self.b = np.random.rand(noutput)-0.5\n",
    "        \n",
    "    def forward (self, x): # propaga un vector x y devuelve la salida\n",
    "        u = np.dot(x, self.w) + self.b              \n",
    "        return np.piecewise(u, [u<0, u>=0], [0,1])\n",
    "                   \n",
    "        \n",
    "    def update (self, x, d, alpha): # realiza una iteración de entrenamiento\n",
    "        s = self.forward(x) # propaga\n",
    "        # Calcula la actualización de los pesos y el sesgo\n",
    "        error = d - s\n",
    "        self.w += alpha * np.outer(x,error)\n",
    "        self.b += error*alpha\n",
    "        \n",
    "               \n",
    "    def RMS (self, X, D): # calcula el error RMS\n",
    "        S = self.forward(X)\n",
    "        return np.mean(np.sqrt(np.mean(np.square(S-D),axis=1)))\n",
    "        \n",
    "    def accuracy (self, X, D): # calcula el ratio de aciertos\n",
    "        S = self.forward(X)\n",
    "        errors = np.mean(np.abs(D-S))\n",
    "        return 1.0 - errors\n",
    "    \n",
    "    def info (self, X, D): # traza de cómno va el entrenamiento\n",
    "        print('     RMS: %6.5f' % self.RMS(X,D))\n",
    "        print('Accuracy: %6.5f' % self.accuracy(X,D))\n",
    "        \n",
    "    def train (self, X, D, alpha, epochs, trace=0): # entrena usando update\n",
    "        for e in range(1,epochs+1):\n",
    "            for i in range(len(X)):\n",
    "                self.update(X[i],D[i], alpha)\n",
    "            if trace!=0 and e%trace == 0:\n",
    "                print('\\n   Epoch: %d' % e)\n",
    "                self.info(X,D)\n",
    "\n",
    "    def from_chromosome(self, chromosome):\n",
    "    # Extraer los pesos y bias de la lista del cromosoma\n",
    "        w_size = self.ninput * self.noutput\n",
    "        w = np.array(chromosome[:w_size]).reshape(self.ninput, self.noutput)\n",
    "        b = np.array(chromosome[w_size:w_size+self.noutput])\n",
    "\n",
    "        # Actualizar los pesos y bias de la red\n",
    "        self.w = w\n",
    "        self.b = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "872b9955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuroevolución\n",
    "# Apartado C de la práctica\n",
    "\n",
    "# construir modelo\n",
    "model = Perceptron(8,4)\n",
    "ch=[-0.061264477472171563, 1.2334191493374835, 0.40603380952043866, 0.9553591142153932, 0.14556935003108212, 0.17990814841861139, -0.8292220744876733, 0.3686721742648328, 0.1958597704484823, 2.3265527364414105, 1.1800661108170107, 1.1311726379626674, 2.4006362522310893, 0.754321877904867, -2.00412648105665, -0.22351230687257362, -0.24490131279372235, -2.5545128379705715, -1.7445478055667343, -1.1100652947300667, 1.9377778639443637, -1.0145382491395563, -2.1039384504087746, 0.5057075365908111, 0.47659236811333505, -0.7576359187542151, -0.3814027318230223, 1.1234334031505608, 1.425999767768399, -0.6016325392277657, 1.2577655010588522, -1.4565977437520088, -0.1549568560654263, 0.025309412884416155, -0.13978695682664993, 2.0723721822560996]\n",
    "model.from_chromosome(ch)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# pasar al modelo los pesos del mejor cromosoma obtenido con SALGA\n",
    "\n",
    "# definir política\n",
    "def policy (observation):\n",
    "    s = model.forward(observation)\n",
    "    action = np.argmax(s)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40a50806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281.2299738492198 0.6406149869246098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "281.2299738492198"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prueba lunar lander por agente\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n",
    "\n",
    "def run ():\n",
    "    #observation, info = env.reset(seed=42)\n",
    "    observation, info = env.reset()\n",
    "    ite = 0\n",
    "    racum = 0\n",
    "    while True:\n",
    "        action = policy(observation)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        \n",
    "        racum += reward\n",
    "\n",
    "        if terminated or truncated:\n",
    "            r = (racum+1000) / 2000\n",
    "            print(racum, r)\n",
    "            return racum\n",
    "    \n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bf4013",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272.88974611928194 0.6364448730596409\n",
      "-18.717192174592213 0.4906414039127039\n",
      "257.7513878131588 0.6288756939065794\n",
      "260.77779969709866 0.6303888998485493\n",
      "244.23650902659745 0.6221182545132988\n",
      "283.3165832682373 0.6416582916341187\n",
      "261.6529327811521 0.6308264663905762\n",
      "255.95490340268566 0.6279774517013428\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "r = 0\n",
    "for _ in range(N):\n",
    "    r += run()\n",
    "    \n",
    "print(r/N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a74dd3",
   "metadata": {},
   "source": [
    "# BIPEDAL WALKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7057970e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# walker\n",
    "import gymnasium as gym\n",
    "env = gym.make(\"BipedalWalker-v3\", render_mode=\"human\")\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69b89947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, ninput, noutput):\n",
    "        self.ninput = ninput\n",
    "        self.noutput = noutput\n",
    "        self.w = np.random.rand(ninput,noutput)-0.5\n",
    "        self.b = np.random.rand(noutput)-0.5\n",
    "        \n",
    "    def forward (self, x): # propaga un vector x y devuelve la salida\n",
    "        u = np.dot(x, self.w) + self.b              \n",
    "        return np.tanh(u)\n",
    "                   \n",
    "        \n",
    "    def update (self, x, d, alpha): # realiza una iteración de entrenamiento\n",
    "        s = self.forward(x) # propaga\n",
    "        # Calcula la actualización de los pesos y el sesgo\n",
    "        error = d - s\n",
    "        self.w += alpha * np.outer(x,error)\n",
    "        self.b += error*alpha\n",
    "        \n",
    "               \n",
    "    def RMS (self, X, D): # calcula el error RMS\n",
    "        S = self.forward(X)\n",
    "        return np.mean(np.sqrt(np.mean(np.square(S-D),axis=1)))\n",
    "        \n",
    "    def accuracy (self, X, D): # calcula el ratio de aciertos\n",
    "        S = self.forward(X)\n",
    "        errors = np.mean(np.abs(D-S))\n",
    "        return 1.0 - errors\n",
    "    \n",
    "    def info (self, X, D): # traza de cómno va el entrenamiento\n",
    "        print('     RMS: %6.5f' % self.RMS(X,D))\n",
    "        print('Accuracy: %6.5f' % self.accuracy(X,D))\n",
    "        \n",
    "    def train (self, X, D, alpha, epochs, trace=0): # entrena usando update\n",
    "        for e in range(1,epochs+1):\n",
    "            for i in range(len(X)):\n",
    "                self.update(X[i],D[i], alpha)\n",
    "            if trace!=0 and e%trace == 0:\n",
    "                print('\\n   Epoch: %d' % e)\n",
    "                self.info(X,D)\n",
    "\n",
    "    def from_chromosome(self, chromosome):\n",
    "    # Extraer los pesos y bias de la lista del cromosoma\n",
    "        w_size = self.ninput * self.noutput\n",
    "        w = np.array(chromosome[:w_size]).reshape(self.ninput, self.noutput)\n",
    "        b = np.array(chromosome[w_size:w_size+self.noutput])\n",
    "\n",
    "        # Actualizar los pesos y bias de la red\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "\n",
    "\n",
    "env = gym.make(\"BipedalWalker-v3\")\n",
    "def fitness(chromosome):\n",
    "    # Crear modelo a partir del cromosoma\n",
    "    model=Perceptron(24,4)\n",
    "    model.from_chromosome(chromosome)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    observation, info = env.reset()\n",
    "    racum = 0\n",
    "    while True:\n",
    "        action = model.forward(observation)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        \n",
    "        racum += reward\n",
    "        \n",
    "    \n",
    "\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "    \n",
    "    racum=(racum+300)/600\n",
    "    return racum\n",
    "\n",
    "parameters={'alphabet':[-3,3], 'type':'floating', 'elitism':True, 'norm':True, 'chromsize':100, 'trace':1,'target':350}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9799154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Perceptron(24,4)\n",
    "ch=[1.023986308924303, -0.4973645499075817, -1.003888092244246, -0.33877646201258416, 0.8268845476265438, -0.28769110211543825, -0.9658192093555964, -1.1716942096488765, -1.2125987471265278, -0.639857079671362, 1.231778602916907, 0.005866748311087959, 1.5301750313575988, 0.7562977972501278, -0.03146905761091112, 1.3624202230311848, -0.36436681048265385, -0.7283845622591405, 0.7153462657868542, -0.20773983642797897, -0.1345047861038423, -0.45873577583525466, 0.14417212270655128, -0.896786879563764, -0.6378723069987962, -2.240694400534288, -0.10748331789345379, 0.755257873526068, 0.7732282186109094, -0.10340785391727067, 0.5504683576898031, 0.12319588657270843, 1.275575266777102, -0.45656323571592944, 0.010600109033453512, 0.6911687492447489, 0.9580698131996964, -0.4088867481491408, -1.2012477766155338, -0.2940256261455885, -0.6037155548846107, -0.523351587456838, -1.7401201664137433, 0.6322261580234979, -1.4803555111056304, -1.1305485757658482, 1.0684811387320812, -1.915694860149524, 0.8729431430447162, 2.2826224685983765, -0.3620924420995166, 1.7903057297800464, 0.11072147665819135, -0.5773534494338569, 0.044999160786314815, -0.7018883956090048, -0.5287107913740653, -0.07691946003890482, -0.39901558006391463, -1.2241555350179547, 1.2969571300425802, 2.09484559073212, -0.3862143102591532, 0.7691321721358817, -0.815890920828555, 1.1968688309987776, 1.0066682327428218, 0.8869321776759773, -0.31945787549116617, 1.419999051853242, -0.6964998566889037, -0.27255852482622567, -2.067542993846906, -0.34112919775150025, 0.7008882686046616, -1.880991180763866, 0.8715301803579907, 0.23750247366769495, 1.4960507986864635, 0.4153029502121958, -1.2269837928827134, 1.9917303385752045, -1.1343566283552886, -0.8985905096991826, 2.543561111920452, -0.8195945980808247, 0.4317066678203291, -1.8049205981407084, 1.1977940906555935, -0.7306747198446832, -0.3044039981339702, 0.526749030010613, 0.5557131988921981, 0.2004691756328618, -1.8258482463775334, 0.8211161493130956, -0.6141975796904973, 0.11897520998920612, 1.0026747065539592, 0.8009842854149878]\n",
    "#ch=[-2.5263419123477333, 2.067202388018617, 0.5732055901969306, -1.9413720757770383, 0.48729605699845824, 1.9472151486411284, 0.07229103029019812, 0.9378047813639271, 0.23504212114212988, 2.252327091097544, -0.3872750881535967, -0.330841294737316, 0.6472530210598538, 0.7876507957140038, 1.3928099203131854, -0.07929236749110302, -1.0089306600768757, 0.4412194816279458, 0.8444519487940507, 0.12627005080605214, 0.4244919415792089, -0.18882669706082797, 0.004603572320672433, -0.7017216013104348, 2.37788330951422, -2.257737129792334, -0.1890974579223581, -0.18578989793673056, -0.06891129436659282, 0.3279774915006987, 0.039980979644790256, 0.20289192064601025, 0.24431801638752837, -0.8804647959472017, -0.9204189088044398, 1.3957458937936913, -0.04136143582160445, -0.5318082694398385, 0.19258813236508077, 0.44293336289520874, 0.43886670664371086, -0.47404266378740945, 0.9179067470780026, 0.596865118875251, -0.21414898855381637, -0.9042220231659213, 0.10177120742049325, -0.9192288707054741, -1.1371215939944719, 0.03788086045605018, 1.5824717756002336, -1.1683153830684456, -0.4975997536357162, 0.3995388193832855, -0.8304541419886641, -1.0292211774958075, -0.3438188464661757, -0.5236617008620069, -0.5152262352444295, 1.2079797547135174, -0.6511145368158043, -1.3100747730214932, -0.16329825809238266, -1.0779604575892818, 0.03795480824895686, -0.042490805055220265, -2.129702098611293, -0.9985904699368048, -1.624990736384832, -0.3979314829457614, -0.6121574926691379, 1.758218319863247, -0.9342562010237847, 1.152619506940568, -0.26241148606206405, -0.3948554752908115, 0.7967645355170333, 0.40813237925463086, 1.1230910015307138, -0.9811635428238249, -2.1666401824390737, -0.3040868365830869, -0.15094791014111, 0.003923732544062086, 0.10268599944333712, 0.024124007496595823, 2.7633180997112454, -0.22852567237673374, -1.8493072900250525, -0.6710129620187862, -0.5046762046059472, -1.684678244539037, -0.6400233616716702, -0.8338219095514375, 1.3363377882266336, -0.5770391365618199, 0.4731282246600117, 0.18492673551332262, 0.2846462034264885, 1.4409603322789446]\n",
    "\n",
    "model.from_chromosome(ch)\n",
    "# pasar al modelo los pesos del mejor cromosoma obtenido con SALGA\n",
    "\n",
    "# definir política\n",
    "def policy (observation):\n",
    "    s = model.forward(observation)\n",
    "    action = s\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9b23900",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251.69787696365063 0.6258489384818253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "251.69787696365063"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"BipedalWalker-v3\", render_mode=\"human\")\n",
    "\n",
    "def run ():\n",
    "    #observation, info = env.reset(seed=42)\n",
    "    observation, info = env.reset()\n",
    "    ite = 0\n",
    "    racum = 0\n",
    "    while True:\n",
    "        action = policy(observation)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        \n",
    "        racum += reward\n",
    "\n",
    "        if terminated or truncated:\n",
    "            r = (racum+1000) / 2000\n",
    "            print(racum, r)\n",
    "            return racum\n",
    "    \n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f6e9577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252.81274025532522 0.6264063701276626\n",
      "253.6212634659151 0.6268106317329575\n",
      "129.98632193382943 0.5649931609669148\n",
      "254.4156580507363 0.6272078290253681\n",
      "253.37127461614602 0.6266856373080729\n",
      "251.9446778625681 0.6259723389312841\n",
      "248.64601900569318 0.6243230095028466\n",
      "254.9063652271091 0.6274531826135545\n",
      "252.8545969820565 0.6264272984910283\n",
      "256.66003901804055 0.6283300195090203\n",
      "240.92189564174197\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "r = 0\n",
    "for _ in range(N):\n",
    "    r += run()\n",
    "    \n",
    "print(r/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5843cfae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
